{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e88faa",
   "metadata": {},
   "source": [
    "# Dataset Generator:\n",
    "- Read low level info from slide.\n",
    "- Extract coordinates from XML.\n",
    "- Generate patches & masks: ROI-guided + corner augmentation\n",
    "- Color normalization: macenko-LS & vahadane-LS.\n",
    "- Background extraction.\n",
    "- Save CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c36bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openslide import OpenSlide, lowlevel \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "from matplotlib import cm\n",
    "import staintools\n",
    "import glob\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238d149",
   "metadata": {},
   "source": [
    "## Reading low level and the region using OpenSlide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b109e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the slides & labels\n",
    "slides_path = '/Users/gabriel.jimenez/Documents/project/AT8Dataset/AT8_wsi/'\n",
    "labels_path = '/Users/gabriel.jimenez/Documents/project/AT8Dataset/AT8_XML_annotations/'\n",
    "\n",
    "######################################################\n",
    "# TODO: glob from folder to read all slides and xmls #\n",
    "######################################################\n",
    "slide_name = 'FAD-APP 717L_P42-06_AT8.ndpi'\n",
    "label_name = 'FAD-APP 717L_P42-06_AT8.xml'\n",
    "\n",
    "# Opening the slide image\n",
    "slide = lowlevel.open(slides_path+slide_name)\n",
    "keys = lowlevel.get_property_names(slide)\n",
    "val = lowlevel.get_property_value(slide,keys[-1])\n",
    "\n",
    "# This are important values for nm -> pixel conversion\n",
    "offsetX = int(lowlevel.get_property_value(slide, 'hamamatsu.XOffsetFromSlideCentre')) # THIS IS IN NANOMETERS!\n",
    "offsetY = int(lowlevel.get_property_value(slide, 'hamamatsu.YOffsetFromSlideCentre')) # THIS IS IN NANOMETERS!\n",
    "\n",
    "resX = float(lowlevel.get_property_value(slide, 'openslide.mpp-x')) # THIS IS IN MICRONS/PIXEL FOR LVL 0!\n",
    "resY = float(lowlevel.get_property_value(slide, 'openslide.mpp-y')) # THIS IS IN MICRONS/PIXEL FOR LVL 0!\n",
    "\n",
    "#######################################################################\n",
    "# TODO: check if all dimensions are in nm (ISSUE: different scanners) #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The slide have  9  magnification levels:\n",
      "   Level 0 (mag x40.0) with dimensions (in pixels) : (119040, 93440).\n",
      "   Level 1 (mag x20.0) with dimensions (in pixels) : (59520, 46720).\n",
      "   Level 2 (mag x10.0) with dimensions (in pixels) : (29760, 23360).\n",
      "   Level 3 (mag x5.0) with dimensions (in pixels) : (14880, 11680).\n",
      "   Level 4 (mag x2.5) with dimensions (in pixels) : (7440, 5840).\n",
      "   Level 5 (mag x1.25) with dimensions (in pixels) : (3720, 2920).\n",
      "   Level 6 (mag x0.625) with dimensions (in pixels) : (1860, 1460).\n",
      "   Level 7 (mag x0.3125) with dimensions (in pixels) : (930, 730).\n",
      "   Level 8 (mag x0.15625) with dimensions (in pixels) : (465, 365).\n"
     ]
    }
   ],
   "source": [
    "slide = OpenSlide(slides_path+slide_name)\n",
    "\n",
    "# Getting slide level dimentions\n",
    "slide_levels = slide.level_dimensions\n",
    "\n",
    "# Printing important information about the current slide\n",
    "print(\"[INFO] The slide have \", len(slide_levels), \" magnification levels:\")\n",
    "for i in range(len(slide_levels)):\n",
    "    print(f\"   Level {i} (mag x{40/2**i}) with dimensions (in pixels) : {slide_levels[i]}.\")\n",
    "\n",
    "# Chosing the magnification level\n",
    "slide_dim_lvl = 2\n",
    "\n",
    "'''\n",
    "TODO: put a flag because this is just for debugging. We only need to load the ROI to RAM #\n",
    "'''\n",
    "# Getting the thumbnail for slide\n",
    "thm = slide.read_region((0, 0), slide_dim_lvl, slide_levels[slide_dim_lvl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3a7a5",
   "metadata": {},
   "source": [
    "## Extracting coordinates from XML and conversion to pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c787418",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "From nano/micro meters to pixel language :) \n",
    "Larger value is X axis (-->)\n",
    "'''\n",
    "dimsSlide = np.array(slide_levels[0])*[resX,resY] # this is in micrometers :)\n",
    "centerPx_X, centerPx_Y = np.array(slide_levels[0])/2\n",
    "_, factor = np.array(slide_levels[0])/np.array(slide_levels[slide_dim_lvl])\n",
    "\n",
    "sizeX, sizeY = np.array(slide_levels[0])/factor\n",
    "\n",
    "# Loading the slide annotations from XML file\n",
    "tree = ET.parse(labels_path+label_name)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Preparing the annotation container\n",
    "labels = []\n",
    "\n",
    "# Getting the annotaiton coordinates from the XML file\n",
    "for boxes in root:\n",
    "    for obejcts in boxes:\n",
    "        type_object = int(obejcts.attrib['Type'])\n",
    "        for vertices in obejcts:\n",
    "            temp_obj = []\n",
    "            for vertex in vertices:\n",
    "                y_mm = float(vertex.attrib['Y']) # this is in milimeters!\n",
    "                x_mm = float(vertex.attrib['X']) # this is in milimeters!\n",
    "                y_p_offset = (y_mm)*1000 - (abs(offsetY)/1000) # this is in micrometers!\n",
    "                x_p_offset = (x_mm)*1000 - (abs(offsetX)/1000) # this is in micrometers!\n",
    "                y_newCenter = y_p_offset + int(centerPx_Y)*resY # this is in micrometers!\n",
    "                x_newCenter = x_p_offset + int(centerPx_X)*resX # this is in micrometers!\n",
    "                y = (y_newCenter/resY)/factor # pixels\n",
    "                x = (x_newCenter/resX)/factor # pixels\n",
    "\n",
    "                ''' Flip '''\n",
    "                y = abs(sizeY - y)\n",
    "                #x = sizeX - x\n",
    "\n",
    "                temp_obj.append([round(x), round(y)])\n",
    "            labels.append([type_object, np.array(temp_obj)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: put a flag because this is just for debugging. We only need to load the ROI to RAM #\n",
    "\n",
    "'''\n",
    "# Overlaying the first object (Gray matter annotation)\n",
    "print(\"\\n[INFO] The whole-slide image with the gray matter annotation (dim level\", slide_dim_lvl, \")\")\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(thm)\n",
    "plt.plot(labels[0][1][:, 0], labels[0][1][:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb15ef",
   "metadata": {},
   "source": [
    "## Generate patches & masks: ROI-guided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a polygone\n",
    "polygon_patch = Polygon(labels[0][1])\n",
    "\n",
    "# Getting the bounding box of the label\n",
    "coords_region = list(polygon_patch.bounds)\n",
    "\n",
    "# Getting the size of the label\n",
    "size = (int(coords_region[2]-coords_region[0])+1, int(coords_region[3]-coords_region[1])+1)\n",
    "\n",
    "# Extracting the region of the label from the whole-slide-image\n",
    "# region = slide.read_region((int(coords_region[0]*factor), int(coords_region[1]*factor)), slide_dim_lvl, (size[0], size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a53015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mask for the WSI\n",
    "mask_ROI = Image.new('L', (int(sizeX), int(sizeY)), 0)\n",
    "mask_obj = Image.new('L', (int(sizeX), int(sizeY)), 0)\n",
    "\n",
    "coords_list = []\n",
    "for obj, coordinates in labels:\n",
    "    if obj == 1: # this are the annotations by Lev.\n",
    "        coordinates2list = coordinates.tolist()\n",
    "        tuples = [tuple(x) for x in coordinates2list]\n",
    "        ImageDraw.Draw(mask_ROI).polygon(tuples, outline=1, fill=1)\n",
    "    \n",
    "    if obj == 2:\n",
    "        coordinates2list = coordinates.tolist()\n",
    "        tuples = [tuple(x) for x in coordinates2list]\n",
    "        ImageDraw.Draw(mask_obj).polygon(tuples, outline=1, fill=1)\n",
    "        \n",
    "        polygon_obj = Polygon(coordinates)\n",
    "        coords_obj = list(polygon_obj.bounds)\n",
    "        coords_list.append(coords_obj)\n",
    "        \n",
    "#mask_ROI_WSI = mask_ROI.crop((coords_region[0],coords_region[1],coords_region[0]+size[0],coords_region[1]+size[1]))\n",
    "#mask_obj_WSI = mask_obj.crop((coords_region[0],coords_region[1],coords_region[0]+size[0],coords_region[1]+size[1]))\n",
    "\n",
    "mask_ROI_WSI = mask_ROI.point(lambda i: i * 255)\n",
    "mask_obj_WSI = mask_obj.point(lambda i: i * 255)\n",
    "\n",
    "'''\n",
    "# Save and plot just to check if it is working properly\n",
    "mask_ROI_WSI.point(lambda i: i * 255).save('./name.png')\n",
    "mask_obj_WSI.point(lambda i: i * 255).save('./name2.png')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(mask_ROI_WSI, cmap = \"gray\")\n",
    "#plt.xlim((coords_region[0], coords_region[2]))\n",
    "#plt.ylim((coords_region[3], coords_region[1]))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(mask_obj_WSI, cmap = \"gray\")\n",
    "#plt.xlim((coords_region[0], coords_region[2]))\n",
    "#plt.ylim((coords_region[3], coords_region[1]))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0bae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code creates the region and its corresponding patches for the 4 corners of data augmentation.\n",
    "'''\n",
    "patchSize = [128, 128] # [cols, rows]\n",
    "save_path = \"./dataset/128x128/\"\n",
    "\n",
    "# mask_WSI: has all the masks for the annotations and is the same size as the WSI.\n",
    "# slide: is the original WSI in the level selected. It is not loaded into RAM yet.\n",
    "# labels: annotations from XML.\n",
    "# coords_list: list of coordinates of annotated objects.\n",
    "\n",
    "k = 0\n",
    "for coords in coords_list: \n",
    "    coords[0] = int(math.floor(coords[0]))\n",
    "    coords[1] = int(math.floor(coords[1]))\n",
    "    coords[2] = int(math.ceil(coords[2]))\n",
    "    coords[3] = int(math.ceil(coords[3]))\n",
    "\n",
    "    size_obj = [coords[2]-coords[0]+1, coords[3]-coords[1]+1]\n",
    "    new_region_size = np.array(patchSize) - np.array(size_obj)        \n",
    "\n",
    "    new_coords = (coords[0]-new_region_size[0]/2, coords[1]-new_region_size[1]/2, coords[2]+new_region_size[0]/2, coords[3]+new_region_size[1]/2)        \n",
    "    new_region_obj = slide.read_region((int(new_coords[0]*factor), int(new_coords[1]*factor)), slide_dim_lvl, (patchSize[0], patchSize[1]))\n",
    "    new_mask_obj = mask_obj_WSI.crop((int(new_coords[0]),int(new_coords[1]),int(new_coords[0]+patchSize[0]),int(new_coords[1]+patchSize[1])))\n",
    "\n",
    "    new_region_obj.save(save_path+\"patches/patch_\"+str(k)+\".png\")\n",
    "    new_mask_obj.save(save_path+\"masks/mask_\"+str(k)+\".png\")\n",
    "\n",
    "    '''\n",
    "    Create 4 additional samples per object/patch ... the annotated object will be in each corner\n",
    "    '''\n",
    "    new_region_corner1 = slide.read_region((int(coords[0]*factor), int(coords[1]*factor)), slide_dim_lvl, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner1 = mask_obj_WSI.crop((coords[0],coords[1],coords[0]+patchSize[0],coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner1.save(save_path+\"patches/patch_\"+str(k)+\"_C1\"+\".png\")\n",
    "    new_mask_corner1.save(save_path+\"masks/mask_\"+str(k)+\"_C1\"+\".png\")\n",
    "\n",
    "    corner2_coords = (coords[2] - patchSize[0], coords[1])\n",
    "    new_region_corner2 = slide.read_region((int(corner2_coords[0]*factor), int(corner2_coords[1]*factor)), slide_dim_lvl, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner2 = mask_obj_WSI.crop((corner2_coords[0],corner2_coords[1],corner2_coords[0]+patchSize[0],corner2_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner2.save(save_path+\"patches/patch_\"+str(k)+\"_C2\"+\".png\")\n",
    "    new_mask_corner2.save(save_path+\"masks/mask_\"+str(k)+\"_C2\"+\".png\")\n",
    "\n",
    "    corner3_coords = (coords[2] - patchSize[0], coords[3] - patchSize[1])\n",
    "    new_region_corner3 = slide.read_region((int(corner3_coords[0]*factor), int(corner3_coords[1]*factor)), slide_dim_lvl, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner3 = mask_obj_WSI.crop((corner3_coords[0],corner3_coords[1],corner3_coords[0]+patchSize[0],corner3_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner3.save(save_path+\"patches/patch_\"+str(k)+\"_C3\"+\".png\")\n",
    "    new_mask_corner3.save(save_path+\"masks/mask_\"+str(k)+\"_C3\"+\".png\")\n",
    "\n",
    "    corner4_coords = (coords[0], coords[3] - patchSize[1])\n",
    "    new_region_corner4 = slide.read_region((int(corner4_coords[0]*factor), int(corner4_coords[1]*factor)), slide_dim_lvl, (patchSize[0], patchSize[1]))\n",
    "    new_mask_corner4 = mask_obj_WSI.crop((corner4_coords[0],corner4_coords[1],corner4_coords[0]+patchSize[0],corner4_coords[1]+patchSize[1]))\n",
    "\n",
    "    new_region_corner4.save(save_path+\"patches/patch_\"+str(k)+\"_C4\"+\".png\")\n",
    "    new_mask_corner4.save(save_path+\"masks/mask_\"+str(k)+\"_C4\"+\".png\")\n",
    "\n",
    "    k += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf64371",
   "metadata": {},
   "source": [
    "## Color normalization: macenko-LS & vahadane-LS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_alternative(image, ref, method, standartize_brightness):\n",
    "    if standartize_brightness:\n",
    "        image = staintools.LuminosityStandardizer.standardize(image)\n",
    "        ref = staintools.LuminosityStandardizer.standardize(ref)\n",
    "            \n",
    "    if method == 'reinhard':\n",
    "        normalizer = staintools.ReinhardColorNormalizer()\n",
    "    if method == 'vahadane':\n",
    "        normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "    if method == 'macenko':\n",
    "        normalizer = staintools.StainNormalizer(method='macenko')\n",
    "            \n",
    "    normalizer.fit(ref)\n",
    "    norm_img = normalizer.transform(image)\n",
    "        \n",
    "    return norm_img  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a646f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is taking a lot of time --> paralelize it! --> threads\n",
    "'''\n",
    "\n",
    "target = staintools.read_image(\"./norm_reference_128x128.png\")\n",
    "folder_patches = '/Users/gabriel.jimenez/Documents/project/togitlab/dataset/128x128/patches/'\n",
    "output_folder_macenko = '/Users/gabriel.jimenez/Documents/project/togitlab/dataset/128x128/macenko/'\n",
    "output_folder_vahadane = '/Users/gabriel.jimenez/Documents/project/togitlab/dataset/128x128/vahadane/'\n",
    "\n",
    "for img in glob.glob(folder_patches+'*.png'):\n",
    "    source = staintools.read_image(img)\n",
    "    norm_img_macenko = normalize_alternative(source, target, 'macenko', True)\n",
    "    output_filename_macenko = output_folder_macenko + img.split('/')[-1]\n",
    "    norm_img_macenko = Image.fromarray(norm_img_macenko)\n",
    "    norm_img_macenko.save(output_filename_macenko)\n",
    "    \n",
    "    norm_img_vahadane = normalize_alternative(source, target, 'vahadane', True)\n",
    "    output_filename_vahadane = output_folder_vahadane + img.split('/')[-1]\n",
    "    norm_img_vahadane = Image.fromarray(norm_img_vahadane)\n",
    "    norm_img_vahadane.save(output_filename_vahadane)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527726e",
   "metadata": {},
   "source": [
    "## Background extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fa525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of region : cols, rows \n",
    "def create_image_patches(img, num_rows, num_columns):\n",
    "    \"\"\"\n",
    "    Partition an image into multiple patches of approximately equal size.\n",
    "    The patch size is based on the desired number of rows and columns.\n",
    "    Returns a list of image patches, in row-major order.\n",
    "    \"\"\"\n",
    "\n",
    "    patch_list = []\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "    w, h = width // num_columns, height // num_rows # // is similar to the floor function\n",
    "    #print(w,h)\n",
    "    \n",
    "    for y in range(0, h*num_rows, num_rows): \n",
    "        y_end = min(y + num_rows, height)\n",
    "        for x in range(0, w*num_columns, num_columns):\n",
    "            x_end = min(x + num_columns, width)\n",
    "            patch = img[y:y_end, x:x_end]\n",
    "            patch_list.append(patch)\n",
    "\n",
    "    return patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093c1ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patchSize = 128\n",
    "\n",
    "background_path = '/Users/gabriel.jimenez/Documents/project/togitlab/dataset/128x128/background/'\n",
    "\n",
    "mask_ROI_WSI = mask_ROI.crop((coords_region[0],coords_region[1],coords_region[0]+size[0],coords_region[1]+size[1]))\n",
    "mask_obj_WSI = mask_obj.crop((coords_region[0],coords_region[1],coords_region[0]+size[0],coords_region[1]+size[1]))\n",
    "region = slide.read_region((int(coords_region[0]*factor), int(coords_region[1]*factor)), slide_dim_lvl, (size[0], size[1]))\n",
    "\n",
    "mask_ROI_WSI = (np.array(mask_ROI_WSI)>0).astype(\"uint8\")\n",
    "mask_obj_WSI = (np.array(mask_obj_WSI)>0).astype(\"uint8\")\n",
    "\n",
    "patch_ROI = create_image_patches(mask_ROI_WSI, patchSize, patchSize)\n",
    "patch_obj = create_image_patches(mask_obj_WSI, patchSize, patchSize)\n",
    "patch_region = create_image_patches(np.array(region), patchSize, patchSize)\n",
    "\n",
    "background_patch = []\n",
    "save_obj = []\n",
    "for i in range(len(patch_ROI)):\n",
    "    pixelSumROI = np.sum(patch_ROI[i])\n",
    "    if pixelSumROI == patchSize*patchSize:\n",
    "        pixelSumObj = np.sum(patch_obj[i])\n",
    "        if pixelSumObj == 0:\n",
    "            background_patch.append(patch_region[i])\n",
    "            Image.fromarray(patch_region[i]).save(background_path + 'bg_' + str(i) + '.png')\n",
    "            #save_obj.append(patch_obj[i])\n",
    "\n",
    "print(len(background_patch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mask_ROI_WSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e93f4c",
   "metadata": {},
   "source": [
    "- Create CSV --> datasetID, WSI_name, WSI_id, CN_id (color normalization), patchID, coords of patch, BOR (background to object ratio)\n",
    "- patchID --> WSIid_patch_nnnn_cX.npy(png) --> c0: object center, c1: top-left, c2: top-right, c3: bottom-right, c4: bottom-left\n",
    "- CN_id --> 1: something, CN_id --> 2: else"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
